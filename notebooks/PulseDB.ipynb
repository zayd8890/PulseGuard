{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ec6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # For numerical computation\n",
    "import pandas as pd # Data manipulation\n",
    "import re\n",
    "import os # system-wide functions\n",
    "import h5py\n",
    "# import scipy.io # reading matlab files in python\n",
    "# from scipy import signal #signal processing\n",
    "# from scipy.fftpack import fft, dct #signal processing\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression #linear regression model\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import KFold, train_test_split # cross validation split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# from matplotlib import pyplot as plt # For plotting graphs(Visualization)\n",
    "# from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb489747",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(390,559):\n",
    "    dict={}\n",
    "    j = f\"{i:03d}\"\n",
    "    file_path = f\"E:/CNR_2025/data/external/PulseDB/PulseDB_Vital/p000{j}.mat\"\n",
    "    output_path = f\"E://CNR_2025//data//raw//PulseDB//PulseDB_Vital//p000{j}.csv\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        continue\n",
    "    \n",
    "\n",
    "    try:\n",
    "        sample_file =h5py.File(file_path, 'r')['Subj_Wins']\n",
    "        for col in range(len(list(sample_file.keys()))):\n",
    "            s = list(sample_file.values())[col]\n",
    "            l = list(sample_file.keys())[col]\n",
    "\n",
    "            dereferenced_content = []\n",
    "\n",
    "            for ref in s[0]:\n",
    "                # Dereference the object reference\n",
    "                dereferenced_data = s.file[ref]\n",
    "                \n",
    "                # Extract the content from the dereferenced object\n",
    "                dereferenced_content.append(dereferenced_data[()])\n",
    "                \n",
    "            merged_array = np.concatenate(dereferenced_content, axis=1).flatten()\n",
    "            merged_list = merged_array.tolist()\n",
    "            dict[s]=merged_list\n",
    "        max_len = max(len(v) for v in dict.values())\n",
    "\n",
    "        for k, v in dict.items():\n",
    "            if len(v) < max_len:\n",
    "                # Find the most frequent value\n",
    "                most_common = Counter(v).most_common(1)[0][0]\n",
    "                # Calculate how many to add\n",
    "                to_add = [most_common] * (max_len - len(v))\n",
    "                # Extend the list\n",
    "                dict[k] = v + to_add\n",
    "\n",
    "        df = pd.DataFrame(dict)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {file_path} due to error: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Saved: E://CNR_2025//data//raw//PulseDB//PulseDB_Vital//p000388.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_file =h5py.File('E:/CNR_2025/data/external/PulseDB/PulseDB_Vital/p000381.mat', 'r')['Subj_Wins']\n",
    "dict={}\n",
    "for col in range(len(list(sample_file.keys()))):\n",
    "    s = list(sample_file.values())[col]\n",
    "    l = list(sample_file.keys())[col]\n",
    "\n",
    "    dereferenced_content = []\n",
    "\n",
    "    for ref in s[0]:\n",
    "        # Dereference the object reference\n",
    "        dereferenced_data = s.file[ref]\n",
    "        \n",
    "        # Extract the content from the dereferenced object\n",
    "        dereferenced_content.append(dereferenced_data[()])\n",
    "        \n",
    "    merged_array = np.concatenate(dereferenced_content, axis=1).flatten()\n",
    "    merged_list = merged_array.tolist()\n",
    "    dict[s]=merged_list\n",
    "max_len = max(len(v) for v in dict.values())\n",
    "\n",
    "for k, v in dict.items():\n",
    "    if len(v) < max_len:\n",
    "        # Find the most frequent value\n",
    "        most_common = Counter(v).most_common(1)[0][0]\n",
    "        # Calculate how many to add\n",
    "        to_add = [most_common] * (max_len - len(v))\n",
    "        # Extend the list\n",
    "        dict[k] = v + to_add\n",
    "        print(f\"Padded key '{k}' with {len(to_add)} x '{most_common}'\")\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "output_path = f\"E://CNR_2025//data//raw//PulseDB//PulseDB_Vital//p000381.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac76ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500,570):\n",
    "    dict={}\n",
    "    j = f\"{i:03d}\"\n",
    "    file_path = f\"E://CNR_2025//data//raw//PulseDB//PulseDB_Vital//p000{j}.csv\"\n",
    "    output_path = f\"E://CNR_2025//data//processed//PulseDB//PulseDB_Vital//p000{j}.csv\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if any('HDF5 dataset' in col for col in df.columns):\n",
    "            df.columns = df.columns.map(lambda col: re.search(r'\"(.*?)\"', col).group(1) if 'HDF5 dataset' in col else col)\n",
    "\n",
    "        selected_columns = [\n",
    "            \"PPG_F\", \"ABP_F\", \"Age\", \"Gender\", \"Height\", \"Weight\", \"BMI\", \"T\", \"SegSBP\", \"SegDBP\"\n",
    "        ]\n",
    "        df = df[selected_columns]\n",
    "\n",
    "        df['Label'] = np.select(\n",
    "            [\n",
    "                (df['SegSBP'] < 120) & (df['SegDBP'] < 80),\n",
    "                (df['SegSBP'] >= 120) & (df['SegSBP'] < 130) & (df['SegDBP'] < 80),\n",
    "                (df['SegSBP'] >= 130) & (df['SegSBP'] < 140) & (df['SegDBP'] >= 80) & (df['SegDBP'] < 90),\n",
    "                (df['SegSBP'] >= 140) & (df['SegDBP'] >= 90),\n",
    "                (df['SegSBP'] > 180) | (df['SegDBP'] > 120)\n",
    "            ],\n",
    "            [\n",
    "                'Normal BP', \n",
    "                'Elevated BP', \n",
    "                'Hypertension Stage 1', \n",
    "                'Hypertension Stage 2', \n",
    "                'Hypertensive Crisis'\n",
    "            ],\n",
    "            default='Normal BP'  # Default value if none of the conditions match\n",
    "        )\n",
    "        df.to_csv(output_path,index=False)\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "        os.remove(file_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {file_path} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the loop ends\n",
    "processed_dir = \"E:/CNR_2025/data/processed/PulseDB/PulseDB_Vital\"\n",
    "\n",
    "\n",
    "csv_files = [os.path.join(processed_dir, f) for f in os.listdir(processed_dir) if f.endswith(\".csv\")]\n",
    "print(csv_files[-1])\n",
    "print(len(csv_files))\n",
    "for i in range(int(len(csv_files)/23)):\n",
    "    all_dfs = []\n",
    "    union_output_path = f\"E:/CNR_2025/data/processed/PulseDB/union_PulseDB_Vital-{i+1}.parquet\"\n",
    "    for csv_file in csv_files[i*23:(i+1)*23]:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {csv_file} due to error: {e}\")\n",
    "    # Concatenate and save the final union CSV\n",
    "    if all_dfs:\n",
    "        union_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        union_df.to_parquet(union_output_path, index=False,engine='pyarrow')\n",
    "        print(f\"Union {i+1}/12 saved to: {union_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e29dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "processed_dir = \"E:/CNR_2025/data/processed/PulseDB/\"\n",
    "\n",
    "# List all .parquet files\n",
    "parquet_files = [os.path.join(processed_dir, f) for f in os.listdir(processed_dir) if f.endswith(\".parquet\")]\n",
    "print(parquet_files[-1])\n",
    "i=0\n",
    "for f in parquet_files:\n",
    "    i+=1\n",
    "    union_output_path=f\"E:/CNR_2025/data/processed/PulseDB/union_PulseDB_Vital-0{i}.parquet\"\n",
    "    try:\n",
    "        df = pd.read_parquet(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {f} due to error: {e}\")\n",
    "        continue\n",
    "    \n",
    "    df_majority = df[df[\"Label\"] == \"Normal BP\"]\n",
    "    df_minority = df[df[\"Label\"] != \"Normal BP\"]\n",
    "    \n",
    "    minority_count = len(df_minority)\n",
    "    \n",
    "    df_majority_downsampled = resample(\n",
    "        df_majority,\n",
    "        replace=False,\n",
    "        n_samples=minority_count,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    df_balanced = pd.concat([df_majority_downsampled, df_minority]).sample(frac=1, random_state=42)\n",
    "    df_balanced.to_parquet(union_output_path, index=False,engine='pyarrow')\n",
    "    print(f\"Union {i+1}/12 saved to: {union_output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73bef0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
